{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VILB4jfh9Wvw"
      },
      "source": [
        "# Sentece BERT for Lyrical Similarity \n",
        "\n",
        "Here, a Sentence BERT model is applyed to attain the similarity of the the unique songs of the DS Project until the end of the Year 2021."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IV2l5mE9mmT"
      },
      "source": [
        "## Loading packages and Models\n",
        "\n",
        "We are using a pretrained BERT Model since our dataset is vast and does not contain a subject-specific vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7xCosNrBuP9"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vcb6oU3v-m0l"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQNxXCSxB0ji"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "import numpy as np \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyZxDjziB8U7"
      },
      "outputs": [],
      "source": [
        "# using a pre-trained Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhGu3MxYDheE"
      },
      "outputs": [],
      "source": [
        "# using a pre-trained Sentence Transformer BERT Model \n",
        "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo9S2FwP_hd4"
      },
      "source": [
        "## Getting the (cleaned) Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDJpvuFB_eI_"
      },
      "outputs": [],
      "source": [
        "## mounting google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_CFCoHt__ME"
      },
      "outputs": [],
      "source": [
        "# reading in data \n",
        "\n",
        "song_data =  pd.read_csv(\"/content/gdrive/My Drive/DS Projekt/data_for_BERT.csv\",  encoding='latin-1')\n",
        "\n",
        "song_data.head()\n",
        "song_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-Gi_2EBhB8F"
      },
      "outputs": [],
      "source": [
        "song_data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeoTMTPBQVj5"
      },
      "outputs": [],
      "source": [
        " song_data['lyrics'].isnull().values.any() ## awesome - so preprocessing has worked ! :D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WljEbLuWET9b"
      },
      "source": [
        "## Applying the Sentence BERT Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS9uAvXlBClj"
      },
      "outputs": [],
      "source": [
        "# getting the embeddings for all songs\n",
        "\n",
        "all_lyrics = list(song_data.lyrics)\n",
        "print(\"The amount of songs considered for the Sentence BERT Model is\", str(len(all_lyrics)), \"!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60X6Q3C4Mh-Z"
      },
      "outputs": [],
      "source": [
        "all_embeddings = model.encode(all_lyrics)\n",
        "all_embeddings.shape # 768 per song\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqxvIuKnEma2"
      },
      "source": [
        "Now, we can store the embeddings together with the combination and genre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOjO7sA4Sz5v"
      },
      "outputs": [],
      "source": [
        "all_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye68kXwbEMGX"
      },
      "outputs": [],
      "source": [
        "all_embeddings_df = pd.DataFrame(all_embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90rv3DttFDqS"
      },
      "outputs": [],
      "source": [
        "all_embeddings_df[\"combination\"] = song_data.combination\n",
        "all_embeddings_df[\"genre\"] = song_data.genre\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EQ7NrBrFQja"
      },
      "outputs": [],
      "source": [
        "# saving to Drive \n",
        "\n",
        "all_embeddings_df.to_csv('/content/gdrive/My Drive/DS Projekt/all_embeddings_df.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIdPGH6bRTPj"
      },
      "outputs": [],
      "source": [
        "## cell for leading in embeddings once the code above has been run!\n",
        "\n",
        "all_embeddings_df = pd.read_csv(\"/content/gdrive/My Drive/DS Projekt/all_embeddings_df.csv\",  encoding='latin-1')\n",
        "\n",
        "print(all_embeddings_df.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQCvWQ47TXYU"
      },
      "outputs": [],
      "source": [
        "all_embeddings_df1 = all_embeddings_df.iloc[1:768]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLtgsP_-SHO9"
      },
      "source": [
        "## Analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpPQW_6DSJKq"
      },
      "source": [
        "### Similarity scores across all songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivHZ-smITswA"
      },
      "outputs": [],
      "source": [
        "embeddings = np.array(all_embeddings_df.iloc[0:24585,1:769])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waYGcVaLZej1"
      },
      "outputs": [],
      "source": [
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yOI2t2b-Dms"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers.util import cos_sim\n",
        "\n",
        "#sim = np.zeros([embeddings.shape[0], embeddings.shape[0] ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zd2PI-c0NLvt"
      },
      "outputs": [],
      "source": [
        "# max 3 values of out similarity list per song!\n",
        "\n",
        "#sim_songs_1 = []\n",
        "#sim_songs_2 = []\n",
        "#sim_songs_3 = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tv1bdr44RzC2"
      },
      "outputs": [],
      "source": [
        "# reading in already calculated data \n",
        "\n",
        "\n",
        "df_sims = pd.read_csv('/content/gdrive/My Drive/DS Projekt/df_sims.csv')\n",
        "\n",
        "\n",
        "sim_songs_1 = list(df_sims.s1)\n",
        "sim_songs_2 = list(df_sims.s2)\n",
        "sim_songs_3 = list(df_sims.s3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T75pg4m344A"
      },
      "outputs": [],
      "source": [
        "len(sim_songs_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpUQx1_ISVwq"
      },
      "outputs": [],
      "source": [
        "\n",
        "for i in range(len(sim_songs_1),embeddings.shape[0]):\n",
        "  \n",
        "  #embeddings.shape[0]):\n",
        "  list_sims = np.ones(embeddings.shape[0])\n",
        "\n",
        "  print(i)\n",
        "  for j in range(embeddings.shape[0]):\n",
        "    list_sims[j] = cos_sim(embeddings[i], embeddings[j])\n",
        "\n",
        "  # same song out \n",
        "  list_sims[i] = -100\n",
        "\n",
        "  # top 1 \n",
        "  top1 = np.argmax(list_sims)\n",
        "\n",
        "  # top 2 \n",
        "  list_sims[top1] = -100\n",
        "  top2 = np.argmax(list_sims)\n",
        "\n",
        "  # top 3\n",
        "  list_sims[top2] = -100\n",
        "  top3 = np.argmax(list_sims)\n",
        "\n",
        "  sim_songs_1.append(str(all_embeddings_df.combination[top1] ))\n",
        "  sim_songs_2.append(str(all_embeddings_df.combination[top2] ))\n",
        "  sim_songs_3.append(str(all_embeddings_df.combination[top3] ))\n",
        "\n",
        "  if i == embeddings.shape[0]:\n",
        "    df_sims = pd.DataFrame({\"s1\":sim_songs_1, \"s2\":sim_songs_2, \"s3\":sim_songs_3})\n",
        "    df_sims.to_csv('/content/gdrive/My Drive/DS Projekt/df_sims.csv')\n",
        "\n",
        "  if (i > 0) & ((i % 400) == 0):\n",
        "    df_sims = pd.DataFrame({\"s1\":sim_songs_1, \"s2\":sim_songs_2, \"s3\":sim_songs_3})\n",
        "    df_sims.to_csv('/content/gdrive/My Drive/DS Projekt/df_sims.csv')\n",
        "\n",
        "#sim.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5Q8j_g0SnlG"
      },
      "source": [
        "assigning top 3 most similar lyrics per song lyric\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTNWzgk1gONF"
      },
      "outputs": [],
      "source": [
        "df_sims = pd.DataFrame({\"s1\":sim_songs_1, \"s2\":sim_songs_2, \"s3\":sim_songs_3})\n",
        "df_sims.shape\n",
        "df_sims.to_csv('/content/gdrive/My Drive/DS Projekt/df_sims.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAyuYcht7w9z"
      },
      "source": [
        "## Merging the string with most similar songs bac togther with the song data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-cETDOp72bF"
      },
      "outputs": [],
      "source": [
        "df_sims = pd.read_csv('/content/gdrive/My Drive/DS Projekt/df_sims.csv')\n",
        "df_sims.shape ## gleich ? wie all_embeddings ?? \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2fodbSS8CjA"
      },
      "outputs": [],
      "source": [
        "all_embeddings_df[\"s1\"] = df_sims.s1\n",
        "all_embeddings_df[\"s2\"] = df_sims.s2\n",
        "all_embeddings_df[\"s3\"] = df_sims.s3\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zBaNrZjgkR8"
      },
      "outputs": [],
      "source": [
        "song_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1sKl6phX24X"
      },
      "outputs": [],
      "source": [
        "## lyrics index liste \n",
        "df_lyrics = song_data[[\"combination\", \"lyrics\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvkGuVPV814T"
      },
      "outputs": [],
      "source": [
        "# init indices in ambeddings data \n",
        "\n",
        "all_embeddings_df[\"index_1\"] = 0\n",
        "all_embeddings_df[\"index_2\"] = 0\n",
        "all_embeddings_df[\"index_3\"] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec7LtrVsgzkO"
      },
      "outputs": [],
      "source": [
        "df_lyrics[\"idx\"] = list(range(24585))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8RDncGWgvg2"
      },
      "outputs": [],
      "source": [
        "all_embeddings_df.index_1[i] =  df_lyrics.index[df_lyrics.combination == all_embeddings_df.s1[i] ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KU1wWk-R9am6"
      },
      "outputs": [],
      "source": [
        "for i in range(all_embeddings_df.shape[0]):\n",
        "  all_embeddings_df.index_1[i] =  list(df_lyrics.idx[df_lyrics.combination == all_embeddings_df.s1[i] ])[0]\n",
        "  all_embeddings_df.index_2[i] =  list(df_lyrics.idx[df_lyrics.combination == all_embeddings_df.s2[i] ])[0]\n",
        "  all_embeddings_df.index_3[i] =  list(df_lyrics.idx[df_lyrics.combination == all_embeddings_df.s3[i] ])[0]\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQvoLOfAjtkk"
      },
      "outputs": [],
      "source": [
        "# checking for different numbers \n",
        "\n",
        "i_s = [20,100,1000,2000,3000,5000,7000,15000,20000]\n",
        "\n",
        "for i in i_s:\n",
        "\n",
        "  print(\"1\")\n",
        "  print(all_embeddings_df.s1[i])\n",
        "  print(df_lyrics.combination[df_lyrics.idx == all_embeddings_df.index_1[i] ])\n",
        "\n",
        "  print(\"2\")\n",
        "  print(all_embeddings_df.s2[i])\n",
        "  print(df_lyrics.combination[df_lyrics.idx == all_embeddings_df.index_2[i] ])\n",
        "\n",
        "  print(\"3\")\n",
        "  print(all_embeddings_df.s3[i])\n",
        "  print(df_lyrics.combination[df_lyrics.idx == all_embeddings_df.index_3[i] ])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0_u0hUulCZj"
      },
      "source": [
        " Awesome!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do3uJmMoSQWK"
      },
      "source": [
        "### Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMLWW0KOlHPa"
      },
      "outputs": [],
      "source": [
        "embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWrXw7WUHO3i"
      },
      "outputs": [],
      "source": [
        "## PCA and plotting for fun \n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=2)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5dVgPZAINQh"
      },
      "outputs": [],
      "source": [
        "## applying PCA\n",
        "principalComponents = pca.fit_transform(embeddings)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZY7pN028vC2"
      },
      "outputs": [],
      "source": [
        "all_embeddings_df[\"p1\"] = principalComponents[:,0]\n",
        "all_embeddings_df[\"p2\"] = principalComponents[:,1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OTbWlyr9ZtU"
      },
      "outputs": [],
      "source": [
        "\n",
        "all_embeddings_df.columns.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW282dVE9DmU"
      },
      "outputs": [],
      "source": [
        "## removing-non-needed columns \n",
        "\n",
        "similarity_resutls_df = all_embeddings_df[[\"combination\", \"s1\", \"s2\", \"s3\", \"p1\", \"p2\", \"genre\", \"index_1\", \"index_2\", \"index_3\"]]\n",
        "similarity_resutls_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaXhOUszAOqw"
      },
      "source": [
        "## Adding in the first date!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExSY81KgmITH"
      },
      "outputs": [],
      "source": [
        "similarity_resutls_df[\"first_appearance\"] = song_data.first_appearance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4moIXLagmozu"
      },
      "source": [
        "## Using one DF for topics modelling and one called \"extra\" for the usage in the similarity Page"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoloiM7XFohz"
      },
      "outputs": [],
      "source": [
        "## removing not known genres for topic modelling\n",
        "\n",
        "similarity_df = similarity_resutls_df[similarity_resutls_df.genre != \"unknown genre\"]\n",
        "\n",
        "similarity_df.to_csv('/content/gdrive/My Drive/DS Projekt/similarity.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38YJV0kLBkEQ"
      },
      "outputs": [],
      "source": [
        "## usage in similarity page \n",
        "\n",
        "similarity_resutls_df.to_csv('/content/gdrive/My Drive/DS Projekt/similarity_extra.csv')\n",
        "df_lyrics.to_csv('/content/gdrive/My Drive/DS Projekt/df_lyrics.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3RJK715XuMu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Kopie von Kopie von Sentence_BERT_for_Lyrical_Similarity.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
